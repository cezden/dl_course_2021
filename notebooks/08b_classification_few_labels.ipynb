{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "16_classification_few_labels_solution.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGBEB7Pvd-0u"
      },
      "source": [
        "# Exercise on the value of unsupervised constructed features for training a classifier with few labeled examples: \n",
        "\n",
        "To get unsupervised constructed features of an image, we can use a pretrained CNN as feature extractor. \n",
        "\n",
        "We have done this to extract features from 100 Cifar10 images.  As pretrained CNN we use a VGG16 architecture that was trained on ImageNet data and was the second winner of the ImageNet competition in 2014. \n",
        "\n",
        "As a check on the quality of the feature representation of the CIFAR10 data, we will use once the pixel-features and once the VGG-features to train a classifier using this 100 labeled data (on average 10 per class). If the VGG-feature are indeed better than the raw pixel values, we would expect to achieve a better classifier when using the VGG-feature compared to the pixel feature.\n",
        "\n",
        "a) Which accuracy would you expect for a classifier which cannot distinguish between the 10 classes and is only guessing?\n",
        "\n",
        "\n",
        "\n",
        "b) Go through the code which is used to set-up, train, and evaluate a CNN classifier using the raw pixel features. Discuss your thoughts on the achieved accuracy (e.g. with your neighbor).\n",
        "\n",
        "\n",
        "b) Now we use the unsupervised constructed VGG features. We want to check, if these VGG features are good enough to train a classifier with only few labeled data and still get a satisfying performance. For this purpose, please complet the code to set up a fully connected NN and run the provided subsequent code to train it and determine its accuracy on the test set. Compare it to the accuracy which we achieve with a RF. Discuss the results (e.g. with your neighbor).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJ_bt5Rd-02"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85458Tp9d-02",
        "outputId": "4359ce5a-b7da-40a7-ff7b-fe4735dfceb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as imgplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pylab import *\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "import sys\n",
        "print (\"Keras {} TF {} Python {}\".format(keras.__version__, tf.__version__, sys.version_info))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras 2.4.3 TF 2.4.1 Python sys.version_info(major=3, minor=7, micro=10, releaselevel='final', serial=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUIuN6nOd-05"
      },
      "source": [
        "### CIFAR Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20_9rgUsd-05",
        "outputId": "5b0c1a30-d488-4d1d-e876-fdd2f9f3e663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#downlad cifar data\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "del [x_test,y_test]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFrSwPeCd-05"
      },
      "source": [
        "#loop over each class label and sample 100 random images over each label and save the idx to subset\n",
        "np.random.seed(seed=222)\n",
        "idx=np.empty(0,dtype=\"int8\")\n",
        "for i in range(0,len(np.unique(y_train))):\n",
        "    idx=np.append(idx,np.random.choice(np.where((y_train[0:len(y_train)])==i)[0],100,replace=False))\n",
        "\n",
        "x_train= x_train[idx]\n",
        "y_train= y_train[idx]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B37tobId-06",
        "outputId": "6b4ebd97-bfac-48bb-8380-e145a0496b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(np.unique(y_train,return_counts=True))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32, 32, 3)\n",
            "(1000, 1)\n",
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmF8lJPed-07"
      },
      "source": [
        "#make train vaild and test\n",
        "#loop over each class label and sample 100 random images over each label and save the idx to subset\n",
        "np.random.seed(seed=123)\n",
        "idx_train=np.empty(0,dtype=\"int8\")\n",
        "for i in range(0,len(np.unique(y_train))):\n",
        "    idx_train=np.append(idx_train,np.random.choice(np.where((y_train[0:len(y_train)])==i)[0],10,replace=False))\n",
        "\n",
        "x_train_new = x_train[idx_train]\n",
        "y_train_new = y_train[idx_train]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqiJHsodd-08"
      },
      "source": [
        "x_test_new=(np.delete(x_train,idx_train,axis=0))\n",
        "y_test_new=(np.delete(y_train,idx_train,axis=0))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuXfHWZvd-09"
      },
      "source": [
        "np.random.seed(seed=127)\n",
        "idx_vaild=np.empty(0,dtype=\"int8\")\n",
        "for i in range(0,len(np.unique(y_test_new))):\n",
        "    idx_vaild=np.append(idx_vaild,np.random.choice(np.where((y_test_new[0:len(y_test_new)])==i)[0],10,replace=False))\n",
        "\n",
        "x_vaild_new = x_test_new[idx_vaild]\n",
        "y_valid_new = y_test_new[idx_vaild]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPzf5eiOd-09"
      },
      "source": [
        "x_test_new=(np.delete(x_test_new,idx_vaild,axis=0))\n",
        "y_test_new=(np.delete(y_test_new,idx_vaild,axis=0))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAjRrwBFd-0-"
      },
      "source": [
        "x_train_new = np.reshape(x_train_new, (100,32,32,3))\n",
        "x_vaild_new = np.reshape(x_vaild_new, (100,32,32,3))\n",
        "x_test_new = np.reshape(x_test_new, (800,32,32,3))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub4bXw51d-0-",
        "outputId": "4fa50cbc-afce-4d6b-e5ed-09fcf59d8aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(np.unique(y_train_new,return_counts=True))\n",
        "print(np.unique(y_valid_new,return_counts=True))\n",
        "print(np.unique(y_test_new,return_counts=True))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10]))\n",
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10]))\n",
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqAPBiZNd-0_"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "y_train_new=to_categorical(y_train_new,10)\n",
        "y_valid_new=to_categorical(y_valid_new,10)\n",
        "y_test_new=to_categorical(y_test_new,10)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdQXPfHUd-0_",
        "outputId": "c506ce5a-a41e-464a-e303-156d8018949f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train_new.shape)\n",
        "print(y_train_new.shape)\n",
        "\n",
        "print(x_vaild_new.shape)\n",
        "print(y_valid_new.shape)\n",
        "\n",
        "print(x_test_new.shape)\n",
        "print(y_test_new.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 32, 32, 3)\n",
            "(100, 10)\n",
            "(100, 32, 32, 3)\n",
            "(100, 10)\n",
            "(800, 32, 32, 3)\n",
            "(800, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hDsmjn4d-1A"
      },
      "source": [
        "# center and standardize the data\n",
        "X_mean = np.mean( x_train_new, axis = 0)\n",
        "X_std = np.std( x_train_new, axis = 0)\n",
        "\n",
        "x_train_new = (x_train_new - X_mean ) / (X_std + 0.0001)\n",
        "x_vaild_new = (x_vaild_new - X_mean ) / (X_std + 0.0001)\n",
        "x_test_new = (x_test_new - X_mean ) / (X_std + 0.0001)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmFjrUIxd-1B"
      },
      "source": [
        "### Setting up the the CNN classifier based on raw image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hOO4d4vd-1B"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6RNdedNd-1B"
      },
      "source": [
        "# here we define  hyperparameter of the NN\n",
        "batch_size = 10\n",
        "nb_classes = 10\n",
        "nb_epoch = 30\n",
        "img_rows, img_cols = 32, 32\n",
        "kernel_size = (3, 3)\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "pool_size = (2, 2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqjynUYMd-1B"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(8, kernel_size,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "model.add(Convolution2D(16, kernel_size,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16,kernel_size,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(40))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4cqyvwZd-1C",
        "outputId": "e32911dc-719c-475b-d5ee-1fe0e141287f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 40)                41000     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 40)                160       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                410       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 46,058\n",
            "Trainable params: 45,882\n",
            "Non-trainable params: 176\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M03zx5y4d-1D",
        "outputId": "4ec06aaf-34b2-401d-f42e-990a422ed049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history=model.fit(x_train_new, y_train_new, \n",
        "                  batch_size=10, \n",
        "                  epochs=30,\n",
        "                  verbose=2, \n",
        "                  validation_data=(x_vaild_new, y_valid_new),shuffle=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10/10 - 2s - loss: 2.7014 - accuracy: 0.1300 - val_loss: 2.2885 - val_accuracy: 0.1400\n",
            "Epoch 2/30\n",
            "10/10 - 0s - loss: 2.0478 - accuracy: 0.2500 - val_loss: 2.2634 - val_accuracy: 0.1600\n",
            "Epoch 3/30\n",
            "10/10 - 0s - loss: 1.7819 - accuracy: 0.3800 - val_loss: 2.2411 - val_accuracy: 0.1400\n",
            "Epoch 4/30\n",
            "10/10 - 0s - loss: 1.5334 - accuracy: 0.5200 - val_loss: 2.2143 - val_accuracy: 0.2100\n",
            "Epoch 5/30\n",
            "10/10 - 0s - loss: 1.3252 - accuracy: 0.6200 - val_loss: 2.2050 - val_accuracy: 0.1800\n",
            "Epoch 6/30\n",
            "10/10 - 0s - loss: 1.2511 - accuracy: 0.6500 - val_loss: 2.2441 - val_accuracy: 0.1600\n",
            "Epoch 7/30\n",
            "10/10 - 0s - loss: 1.1097 - accuracy: 0.7200 - val_loss: 2.2666 - val_accuracy: 0.1600\n",
            "Epoch 8/30\n",
            "10/10 - 0s - loss: 0.9868 - accuracy: 0.7500 - val_loss: 2.2543 - val_accuracy: 0.1600\n",
            "Epoch 9/30\n",
            "10/10 - 0s - loss: 0.7885 - accuracy: 0.8600 - val_loss: 2.2802 - val_accuracy: 0.1400\n",
            "Epoch 10/30\n",
            "10/10 - 0s - loss: 0.8120 - accuracy: 0.8400 - val_loss: 2.3055 - val_accuracy: 0.1400\n",
            "Epoch 11/30\n",
            "10/10 - 0s - loss: 0.6882 - accuracy: 0.8900 - val_loss: 2.3118 - val_accuracy: 0.1200\n",
            "Epoch 12/30\n",
            "10/10 - 0s - loss: 0.7086 - accuracy: 0.8700 - val_loss: 2.2855 - val_accuracy: 0.1500\n",
            "Epoch 13/30\n",
            "10/10 - 0s - loss: 0.6894 - accuracy: 0.9000 - val_loss: 2.3258 - val_accuracy: 0.1400\n",
            "Epoch 14/30\n",
            "10/10 - 0s - loss: 0.6678 - accuracy: 0.8800 - val_loss: 2.3598 - val_accuracy: 0.1400\n",
            "Epoch 15/30\n",
            "10/10 - 0s - loss: 0.5449 - accuracy: 0.9000 - val_loss: 2.3204 - val_accuracy: 0.1300\n",
            "Epoch 16/30\n",
            "10/10 - 0s - loss: 0.5092 - accuracy: 0.9500 - val_loss: 2.3396 - val_accuracy: 0.1600\n",
            "Epoch 17/30\n",
            "10/10 - 0s - loss: 0.4981 - accuracy: 0.9600 - val_loss: 2.3116 - val_accuracy: 0.1600\n",
            "Epoch 18/30\n",
            "10/10 - 0s - loss: 0.4578 - accuracy: 0.9700 - val_loss: 2.3167 - val_accuracy: 0.1700\n",
            "Epoch 19/30\n",
            "10/10 - 0s - loss: 0.3992 - accuracy: 0.9800 - val_loss: 2.3140 - val_accuracy: 0.1500\n",
            "Epoch 20/30\n",
            "10/10 - 0s - loss: 0.3687 - accuracy: 0.9800 - val_loss: 2.3113 - val_accuracy: 0.1700\n",
            "Epoch 21/30\n",
            "10/10 - 0s - loss: 0.3430 - accuracy: 0.9900 - val_loss: 2.2851 - val_accuracy: 0.1900\n",
            "Epoch 22/30\n",
            "10/10 - 0s - loss: 0.4037 - accuracy: 0.9600 - val_loss: 2.2846 - val_accuracy: 0.2000\n",
            "Epoch 23/30\n",
            "10/10 - 0s - loss: 0.3409 - accuracy: 0.9900 - val_loss: 2.3038 - val_accuracy: 0.2100\n",
            "Epoch 24/30\n",
            "10/10 - 0s - loss: 0.2885 - accuracy: 0.9800 - val_loss: 2.2937 - val_accuracy: 0.2300\n",
            "Epoch 25/30\n",
            "10/10 - 0s - loss: 0.3475 - accuracy: 0.9800 - val_loss: 2.3023 - val_accuracy: 0.2200\n",
            "Epoch 26/30\n",
            "10/10 - 0s - loss: 0.2316 - accuracy: 1.0000 - val_loss: 2.2971 - val_accuracy: 0.2200\n",
            "Epoch 27/30\n",
            "10/10 - 0s - loss: 0.2664 - accuracy: 0.9800 - val_loss: 2.3252 - val_accuracy: 0.1900\n",
            "Epoch 28/30\n",
            "10/10 - 0s - loss: 0.2415 - accuracy: 1.0000 - val_loss: 2.3940 - val_accuracy: 0.1800\n",
            "Epoch 29/30\n",
            "10/10 - 0s - loss: 0.2102 - accuracy: 0.9800 - val_loss: 2.3256 - val_accuracy: 0.2200\n",
            "Epoch 30/30\n",
            "10/10 - 0s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.3044 - val_accuracy: 0.2200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7kEbIcad-1D"
      },
      "source": [
        "### Evaluation of the CNN classifier that was trained on raw image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYcyO4N4d-1E",
        "outputId": "6eea955c-6096-4c5c-d920-1619f966b1d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pred=model.predict(x_test_new)\n",
        "print(confusion_matrix(np.argmax(y_test_new,axis=1),np.argmax(pred,axis=1)))\n",
        "print(\"Acc = \" ,np.sum(np.argmax(y_test_new,axis=1)==np.argmax(pred,axis=1))/len(y_test_new))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[36  6  6  6  3  0  1  1 16  5]\n",
            " [ 7 16  5  2  8  4  3  2 18 15]\n",
            " [ 3  5 17  7 27  0  8  0 10  3]\n",
            " [ 0  9 17 15 14  2 17  0  4  2]\n",
            " [ 5  5  8  6 28  2 12  0 13  1]\n",
            " [ 5  5 11 13 19  7 10  3  6  1]\n",
            " [ 4  4 10 13 22  2 21  1  1  2]\n",
            " [ 4  2 10  9 24  4  5 10  9  3]\n",
            " [18  2  8  3  5  2  3  2 31  6]\n",
            " [ 5 10  7  4 13  3  3  1 19 15]]\n",
            "Acc =  0.245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5k7FBald-1E"
      },
      "source": [
        "### Getting the VGG features for CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQH8us4Bd-1F",
        "outputId": "53faef3e-5f2b-49bb-b6e2-eedf3a344cc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Downloading embeddings\n",
        "import urllib\n",
        "import os\n",
        "if not os.path.isfile('cifar_EMB_1000.npz'):\n",
        "    urllib.request.urlretrieve(\n",
        "    \"https://www.dropbox.com/s/si287al91c1ls0d/cifar_EMB_1000.npz?dl=1\",\n",
        "    \"cifar_EMB_1000.npz\")\n",
        "%ls -hl cifar_EMB_1000.npz"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 18M Mar  8 20:41 cifar_EMB_1000.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bux3xwf0d-1F"
      },
      "source": [
        "Data=np.load(\"cifar_EMB_1000.npz\")\n",
        "vgg_features_cifar = Data[\"arr_0\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUrY5ekd-1F"
      },
      "source": [
        "vgg_features_cifar_train = vgg_features_cifar[idx_train]\n",
        "vgg_features_cifar_test=(np.delete(vgg_features_cifar,idx_train,axis=0))\n",
        "vgg_features_cifar_valid = vgg_features_cifar_test[idx_vaild]\n",
        "vgg_features_cifar_test=(np.delete(vgg_features_cifar_test,idx_vaild,axis=0))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZCEIourd-1G",
        "outputId": "8c5981ab-f219-44e3-e04a-eb7ae77bffee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vgg_features_cifar_train.shape)\n",
        "print(vgg_features_cifar_valid.shape)\n",
        "print(vgg_features_cifar_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4096)\n",
            "(100, 4096)\n",
            "(800, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXkrEaXKd-1G"
      },
      "source": [
        "### Setting up the the CNN classifier based on VGG feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN12Ss4md-1H"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200,batch_input_shape=(None, 4096)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(200))\n",
        "\n",
        "#### we still need to add the last layers to get the predictions on the 10 classes\n",
        "### your code here\n",
        "\n",
        "\n",
        "####### end of your code ######\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQXpgHtd-1H",
        "outputId": "c1533b58-9f44-4af2-efd8-cd797b88618a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 200)               819400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                2010      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 862,410\n",
            "Trainable params: 862,010\n",
            "Non-trainable params: 400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK45pvVCd-1H",
        "outputId": "5d60bf78-eb8c-4864-905e-b6bdfd780542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history=model.fit(vgg_features_cifar_train, y_train_new, \n",
        "                  batch_size=10, \n",
        "                  epochs=20,\n",
        "                  verbose=2, \n",
        "                  validation_data=(vgg_features_cifar_valid, y_valid_new),shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 - 1s - loss: 2.3058 - accuracy: 0.2400 - val_loss: 7.8908 - val_accuracy: 0.3400\n",
            "Epoch 2/20\n",
            "10/10 - 0s - loss: 1.0309 - accuracy: 0.6500 - val_loss: 5.0176 - val_accuracy: 0.3900\n",
            "Epoch 3/20\n",
            "10/10 - 0s - loss: 0.6810 - accuracy: 0.8000 - val_loss: 3.8941 - val_accuracy: 0.4000\n",
            "Epoch 4/20\n",
            "10/10 - 0s - loss: 0.5009 - accuracy: 0.8600 - val_loss: 2.7359 - val_accuracy: 0.4700\n",
            "Epoch 5/20\n",
            "10/10 - 0s - loss: 0.3253 - accuracy: 0.9100 - val_loss: 2.2944 - val_accuracy: 0.5100\n",
            "Epoch 6/20\n",
            "10/10 - 0s - loss: 0.3167 - accuracy: 0.8800 - val_loss: 2.1687 - val_accuracy: 0.5100\n",
            "Epoch 7/20\n",
            "10/10 - 0s - loss: 0.2178 - accuracy: 0.9400 - val_loss: 2.1188 - val_accuracy: 0.5100\n",
            "Epoch 8/20\n",
            "10/10 - 0s - loss: 0.2724 - accuracy: 0.8900 - val_loss: 2.1433 - val_accuracy: 0.5300\n",
            "Epoch 9/20\n",
            "10/10 - 0s - loss: 0.1461 - accuracy: 0.9700 - val_loss: 2.1637 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "10/10 - 0s - loss: 0.1870 - accuracy: 0.9500 - val_loss: 1.9074 - val_accuracy: 0.5400\n",
            "Epoch 11/20\n",
            "10/10 - 0s - loss: 0.2335 - accuracy: 0.9300 - val_loss: 1.8241 - val_accuracy: 0.5500\n",
            "Epoch 12/20\n",
            "10/10 - 0s - loss: 0.1066 - accuracy: 0.9900 - val_loss: 1.9091 - val_accuracy: 0.5400\n",
            "Epoch 13/20\n",
            "10/10 - 0s - loss: 0.1088 - accuracy: 0.9700 - val_loss: 1.9038 - val_accuracy: 0.5400\n",
            "Epoch 14/20\n",
            "10/10 - 0s - loss: 0.1251 - accuracy: 0.9700 - val_loss: 1.8486 - val_accuracy: 0.5500\n",
            "Epoch 15/20\n",
            "10/10 - 0s - loss: 0.0999 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.5500\n",
            "Epoch 16/20\n",
            "10/10 - 0s - loss: 0.0569 - accuracy: 0.9800 - val_loss: 1.7529 - val_accuracy: 0.5700\n",
            "Epoch 17/20\n",
            "10/10 - 0s - loss: 0.0601 - accuracy: 0.9900 - val_loss: 1.7895 - val_accuracy: 0.5700\n",
            "Epoch 18/20\n",
            "10/10 - 0s - loss: 0.0705 - accuracy: 0.9800 - val_loss: 1.8240 - val_accuracy: 0.5700\n",
            "Epoch 19/20\n",
            "10/10 - 0s - loss: 0.0757 - accuracy: 0.9800 - val_loss: 1.9342 - val_accuracy: 0.5400\n",
            "Epoch 20/20\n",
            "10/10 - 0s - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.9484 - val_accuracy: 0.5300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlHwGiRsd-1I"
      },
      "source": [
        "### Evaluation of the CNN classifier that was trained on VGG features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80mCdjkWd-1I",
        "outputId": "d491e0cf-944d-404e-fd39-df1a99725e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred=model.predict(vgg_features_cifar_test)\n",
        "\n",
        "#### we now want to get the confusion matrix for the predictions on the test data\n",
        "### your code here\n",
        "\n",
        "\n",
        "########## end of your code ###############################\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[31  1  5  1  1  1  0  1 34  5]\n",
            " [ 1 66  0  0  1  0  0  1  6  5]\n",
            " [ 8  1 26  3 23  6  6  1  5  1]\n",
            " [ 0  1  1 26  3 17 13  3 10  6]\n",
            " [ 0  0  0  0 52  3  7 10  7  1]\n",
            " [ 0  0  0 18  5 47  2  8  0  0]\n",
            " [ 4  0 16  1 11  2 44  1  1  0]\n",
            " [ 0  0  0  3 23  5  0 44  4  1]\n",
            " [ 1  1  0  0  0  0  0  2 74  2]\n",
            " [ 0 19  0  0  2  1  0  0  7 51]]\n",
            "Acc =  0.57625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ym3NgNd-1I"
      },
      "source": [
        "### Baseline: use VGG feature to train a Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ljtLiwd-1I",
        "outputId": "f67dfb42-b7a1-49fb-ea38-c44ddceba6d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(vgg_features_cifar_train,np.argmax(y_train_new, axis=1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsIVx7zd-1J",
        "outputId": "22b48f25-6db9-467f-fa09-abd4b7b7aa52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "pred=clf.predict(vgg_features_cifar_test)\n",
        "print(confusion_matrix(np.argmax(y_test_new, axis=1), pred))\n",
        "np.sum(pred==np.argmax(y_test_new, axis=1))/len(np.argmax(y_test_new, axis=1))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35  2  4  1  0  0  1  3 27  7]\n",
            " [ 2 61  0  0  2  0  0  0  5 10]\n",
            " [ 8  2 21 11 22  7  4  3  1  1]\n",
            " [ 3  0  8 27  0 18 11  6  2  5]\n",
            " [ 0  0 10  6 38  2  4 14  5  1]\n",
            " [ 3  0  1 17  2 47  1  9  0  0]\n",
            " [ 3  0 19  5  7  5 38  3  0  0]\n",
            " [ 1  0  0  6 16  3  0 51  1  2]\n",
            " [ 8  4  2  3  0  0  0  0 58  5]\n",
            " [ 0 19  0  0  1  0  0  0  4 56]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ZX9Kqdd-1J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
