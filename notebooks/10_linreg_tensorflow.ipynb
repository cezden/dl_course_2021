{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_linreg_tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O2sP8Kwe7L9Z"
      },
      "source": [
        "## Fitting a linear regression model with TensorFlow\n",
        "\n",
        "In this notebook you will see how to use TensorFlow to fit the parameters (slope and intercept) of a simple linear regression model via gradient descent (GD). \n",
        "\n",
        "**Dataset:** You work with the systolic blood pressure and age data of 33 American women, which is generated and visualized in the upper part of the notebook. \n",
        "\n",
        "**Content:**\n",
        "\n",
        "* fit a linear model via the sklearn machine learning library of python to get the fitted values of the intercept and slope as reference. \n",
        "* use the TensorFlow library to fit the parameter of the simple linear model via GD with the objective to minimize the MSE loss. \n",
        "    * define the computational graph of the model\n",
        "    * define the loss and the optimizer\n",
        "    * visualize the computational graph in tensorboard\n",
        "    * fit the model parameters via GD and check the current values of the estimated model parameters and the loss after each updatestep\n",
        "    * verify that the estimated parameters converge to the values which you got from the sklearn fit.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IxDnHMLUL64a"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZBbVOY-8GT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Ns6420jRmbQ",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "plt.style.use('default')\n",
        "from sklearn.linear_model import LinearRegression\n",
        "%load_ext tensorboard\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3c9bh7zMVhP"
      },
      "source": [
        "Here we read in the systolic blood pressure and the age of the 33 American women in our dataset. Then we use the sklearn library to find the optimal values for the slope a and the intercept b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h5NlSPsPSFR-",
        "colab": {}
      },
      "source": [
        "# Blood Pressure data\n",
        "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
        "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
        "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
        "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
        "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
        "x = np.asarray(x, np.float32) \n",
        "y = np.asarray(y, np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cFR-y-HER-Uo",
        "colab": {}
      },
      "source": [
        "plt.scatter(x=x,y=y)\n",
        "plt.title(\"blood pressure vs age\")\n",
        "plt.xlabel(\"x (age)\")\n",
        "plt.ylabel(\"y (sbp)\")\n",
        "\n",
        "model = LinearRegression()\n",
        "res = model.fit(x.reshape((len(x),1)), y)\n",
        "predictions = model.predict(x.reshape((len(x),1)))\n",
        "plt.plot(x, predictions)\n",
        "plt.show()\n",
        "print(\"intercept = \",res.intercept_,\"solpe = \", res.coef_[0],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxlyNp9uSKYd"
      },
      "source": [
        "## Tensorflow\n",
        "\n",
        "We now use Tensorflow to define the computational graph then we will run the graph and automatically get the gradients of the loss w.r.t the variables (slope a  and intercept b) to update them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LiNOds2vSOz8",
        "colab": {}
      },
      "source": [
        "# Defining the graph (construction phase)\n",
        "\n",
        "@tf.function\n",
        "def my_func(a_, b_):\n",
        "  x_  = tf.constant(x, name='x_const')                     # Constants, these are fixed tensors holding the data values and cannot be changed by the optimization\n",
        "  y_  = tf.constant(y, name='y_const')  \n",
        "\n",
        "  y_hat_ = a_*x_ + b_                                      # we symbolically calculate y_hat    \n",
        "  loss_ = tf.reduce_mean(tf.square(y_ - y_hat_))           # The final result, the MSE. Still symbolical\n",
        "  return loss_\n",
        "\n",
        "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values, will be optimized later\n",
        "b_  = tf.Variable(139.0, name='b_var')                     # we name them so that they look nicer in the graph\n",
        "\n",
        "logdir=\"linreg/\"\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "z = my_func(a_, b_)   #needs one call to write the graph\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export( \n",
        "      name=\"linreg_tensorboard\",\n",
        "      step=0,\n",
        "      profiler_outdir=logdir)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16iKQnOB8fq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir linreg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nkS4XL2QtxJk"
      },
      "source": [
        "####Let's run the Graph and feed our start values for slope a and intercept b and fetch the mse loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "91qRdJJkqNrY",
        "colab": {}
      },
      "source": [
        "res_val =my_func(a_, b_)                        # Letting the variables a=0 b=139 flow through the graph\n",
        "res_val\n",
        "res_val.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RmVO643pRWzM"
      },
      "source": [
        "Now we add an optimizer (gradient descent) to the graph and opimize the slope a and the intercept b. The start values are a=0 and b=139 (139 is the mean of the blood pressure and slope a=0 implies that the model predicts the mean for each age). We set a learning rate  and do 80000 updatesteps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2StYA16v4vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values\n",
        "b_  = tf.Variable(139.0, name='b_var')                     # \n",
        "optimizer = tf.keras.optimizers.Adam()                     # sgd optimizer with the learning rate\n",
        "for i in range(80000): \n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = my_func(a_,b_)\n",
        "    gradients = tape.gradient(loss, [a_,b_])\n",
        "    optimizer.apply_gradients(zip(gradients,[a_,b_])) \n",
        "  if ((i==1)|(i==2)|(i==3)): \n",
        "        print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy()) \n",
        "  if (i % 5000 == 0): \n",
        "        print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IZgcbnOFVRxs"
      },
      "source": [
        "Let's look at the final values for the slope a and the intercept b. Form the sklearn solution we know that:\n",
        "\n",
        "1.   optimal value for a:   1.1050216\n",
        "2.   optimal value for b:   87.67143\n",
        "3.   minimal loss:         349.200787168560\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ElBejUYn0u7Q",
        "colab": {}
      },
      "source": [
        " print(a_.numpy(), b_.numpy(), loss.numpy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMqiXRZ9EMfh",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Compre the opitmal values from tensorflow with the ones from sklean.  \n",
        "Do you get the same?    \n",
        "Try to explain the differences and change the code to get the same results.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V164z0rB4h1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
